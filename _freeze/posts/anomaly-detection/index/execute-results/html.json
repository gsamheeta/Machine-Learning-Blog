{
  "hash": "0b81b848351f791507f0e3e2da23479a",
  "result": {
    "markdown": "---\ntitle: Anomaly/Outlier detection\nauthor: Samheeta\ndate: 2023-12-6\ndescription: 'Anomaly detection in Machine Learning focuses on identifying rare or unusual instances in data that significantly differ from the majority of normal observations, aiding in the detection of outliers or irregular patterns.'\n---\n\n**Contents:**\n\n-   Introduction to Anomaly or Outlier Detection.\n\n-   Example of Anomaly Detection with real data [Credit Card dataset](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud) \n\n-   Data Visualization\n\n-   Data processing\n\n-   Anomaly Detection\n\n#### **Anomaly or Outlier Detection**\n\nAnomaly or outlier detection is a crucial aspect of data analysis and machine learning, involving the identification of data points or observations that deviate significantly from the expected or normal behavior within a dataset. These anomalies, often representing rare events, errors, or unusual patterns, are detected using various techniques such as statistical methods, machine learning algorithms, distance-based approaches, and domain-specific rules, enabling their recognition in applications like fraud detection, quality control, network security, and predictive maintenance, ultimately enhancing decision-making and problem-solving in diverse fields.\n\nIn the context of machine learning, anomaly detection can be approached using various techniques and algorithms, including:\n\n- Statistical Methods: Statistical approaches involve using statistical measures such as mean, standard deviation, and probability distributions to identify outliers. Data points that fall outside predefined statistical thresholds are considered anomalies.\n\n- Machine Learning Algorithms: Machine learning models can be trained to detect anomalies. Some popular algorithms for this purpose include:\n\nOne-Class SVM (Support Vector Machine): It is a supervised learning algorithm that learns to classify data points as either \"normal\" or \"anomalous\" based on the majority class (usually \"normal\" data).\n\nIsolation Forest: This algorithm isolates anomalies by recursively partitioning the data into subsets, making it efficient for high-dimensional datasets.\n\nAutoencoders: These neural networks are used for unsupervised learning and can learn to reconstruct normal data. Data points that are poorly reconstructed are considered anomalies.\n\n- Distance-Based Methods: These methods compute distances or dissimilarities between data points and identify outliers as those with unusually large distances from their nearest neighbors. k-nearest neighbors (KNN) and DBSCAN (Density-Based Spatial Clustering of Applications with Noise) are examples of distance-based techniques.\n\n- Time Series Anomaly Detection: In time series data, specialized methods like Seasonal Decomposition of Time Series (STL), Exponential Smoothing, or Recurrent Neural Networks (RNNs) can be used to detect anomalies over time.\n\n- Rule-Based Systems: Domain-specific knowledge can be applied to define rules that identify anomalies based on specific criteria. This approach is often used in fields like cybersecurity.\n\n- Unsupervised and Semi-Supervised Learning: Anomaly detection can be performed in an unsupervised manner, where the model learns from data without the need for labeled anomalies, or in a semi-supervised manner with a limited amount of labeled data.\n\nThe choice of method depends on the characteristics of the data, the specific problem, and the available resources. Anomaly detection is a valuable tool in machine learning for uncovering irregularities and potential issues within datasets, leading to improved decision-making and problem-solving in various domains.\n\n## Importing libraries\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\n# File system manangement\nimport time, psutil, os, gc\n\n# Mathematical functions\nimport math\n\n# Data manipulation\nimport numpy as np\nimport pandas as pd\n\n# Plotting and visualization\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\nimport seaborn as sns\nsns.set_theme()\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\n\n# Train-test split\nfrom sklearn.model_selection import train_test_split\n\n# Progress bar for loop\nfrom tqdm.contrib import itertools\n```\n:::\n\n\n## Runtime and memory usage\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\n# Recording the starting time, complemented with a stopping time check in the end to compute process runtime\nstart = time.time()\n\n# Class representing the OS process and having memory_info() method to compute process memory usage\nprocess = psutil.Process(os.getpid())\n```\n:::\n\n\nThe Anomaly Detection in credit card transactions is aiming to identify fraudulent transactions among a highly imbalanced dataset. Anomalies, or outliers, are rare observations that deviate significantly from the majority of data points. Anomaly detection techniques, including machine learning, are employed to automate this process. The project's objective is to fit a probability distribution based on authentic transactions and use it to identify new transactions as authentic or fraudulent, with the target variable playing no role in constructing the distribution.\n\nThe evaluation metric considers True Positives (correctly predicting positive outcomes), True Negatives (correctly predicting negative outcomes), False Positives (incorrectly predicting positive outcomes), and False Negatives (incorrectly predicting negative outcomes). Metrics like Precision, Recall, F1-Score, and MCC are used to evaluate model performance. F2-Score is given special importance due to the higher cost associated with false negatives in this context.\n\nFeature selection is crucial due to high dimensionality, with 30 features in the dataset. Features are selected based on their ability to distinguish between authentic and fraudulent transactions, considering the distributions of each feature for both target classes. Features exhibiting distinct distributions are retained for classification purposes.\n\nThe dataset contains information on credit card transactions made by European cardholders and can be accessed via Kaggle. The data includes transaction time, PCA-transformed features (V1 to V28), transaction amount, and a binary class variable indicating authenticity (0 for authentic, 1 for fraudulent).\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\n# Loading the data\ndata = pd.read_csv('C:/Users/Lenovo/Desktop/MLBlog-gh-pages/posts/anomaly-detection/creditcard.csv')\nprint(pd.Series({\"Memory usage\": \"{:.2f} MB\".format(data.memory_usage().sum()/(1024*1024)),\n                 \"Dataset shape\": \"{}\".format(data.shape)}).to_string())\ndata.head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMemory usage         67.36 MB\nDataset shape    (284807, 31)\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=3}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>-1.359807</td>\n      <td>-0.072781</td>\n      <td>2.536347</td>\n      <td>1.378155</td>\n      <td>-0.338321</td>\n      <td>0.462388</td>\n      <td>0.239599</td>\n      <td>0.098698</td>\n      <td>0.363787</td>\n      <td>...</td>\n      <td>-0.018307</td>\n      <td>0.277838</td>\n      <td>-0.110474</td>\n      <td>0.066928</td>\n      <td>0.128539</td>\n      <td>-0.189115</td>\n      <td>0.133558</td>\n      <td>-0.021053</td>\n      <td>149.62</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>1.191857</td>\n      <td>0.266151</td>\n      <td>0.166480</td>\n      <td>0.448154</td>\n      <td>0.060018</td>\n      <td>-0.082361</td>\n      <td>-0.078803</td>\n      <td>0.085102</td>\n      <td>-0.255425</td>\n      <td>...</td>\n      <td>-0.225775</td>\n      <td>-0.638672</td>\n      <td>0.101288</td>\n      <td>-0.339846</td>\n      <td>0.167170</td>\n      <td>0.125895</td>\n      <td>-0.008983</td>\n      <td>0.014724</td>\n      <td>2.69</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>-1.358354</td>\n      <td>-1.340163</td>\n      <td>1.773209</td>\n      <td>0.379780</td>\n      <td>-0.503198</td>\n      <td>1.800499</td>\n      <td>0.791461</td>\n      <td>0.247676</td>\n      <td>-1.514654</td>\n      <td>...</td>\n      <td>0.247998</td>\n      <td>0.771679</td>\n      <td>0.909412</td>\n      <td>-0.689281</td>\n      <td>-0.327642</td>\n      <td>-0.139097</td>\n      <td>-0.055353</td>\n      <td>-0.059752</td>\n      <td>378.66</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>-0.966272</td>\n      <td>-0.185226</td>\n      <td>1.792993</td>\n      <td>-0.863291</td>\n      <td>-0.010309</td>\n      <td>1.247203</td>\n      <td>0.237609</td>\n      <td>0.377436</td>\n      <td>-1.387024</td>\n      <td>...</td>\n      <td>-0.108300</td>\n      <td>0.005274</td>\n      <td>-0.190321</td>\n      <td>-1.175575</td>\n      <td>0.647376</td>\n      <td>-0.221929</td>\n      <td>0.062723</td>\n      <td>0.061458</td>\n      <td>123.50</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.0</td>\n      <td>-1.158233</td>\n      <td>0.877737</td>\n      <td>1.548718</td>\n      <td>0.403034</td>\n      <td>-0.407193</td>\n      <td>0.095921</td>\n      <td>0.592941</td>\n      <td>-0.270533</td>\n      <td>0.817739</td>\n      <td>...</td>\n      <td>-0.009431</td>\n      <td>0.798278</td>\n      <td>-0.137458</td>\n      <td>0.141267</td>\n      <td>-0.206010</td>\n      <td>0.502292</td>\n      <td>0.219422</td>\n      <td>0.215153</td>\n      <td>69.99</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 31 columns</p>\n</div>\n```\n:::\n:::\n\n\n## Train-Validation-Test Split\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\n# Splitting the data by target class\ndata_0, data_1 = data[data['Class'] == 0], data[data['Class'] == 1]\n\n# Feature-target split\nX_0, y_0 = data_0.drop('Class', axis = 1), data_0['Class']\nX_1, y_1 = data_1.drop('Class', axis = 1), data_1['Class']\n\n# Splitting the authentic class and constructing the training set\nX_train, X_test, y_train, y_test = train_test_split(X_0, y_0, test_size = 0.2, random_state = 40)\nX_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size = 0.5, random_state = 40)\ndata_val_1, data_test_1 = pd.concat([X_val, y_val], axis = 1), pd.concat([X_test, y_test], axis = 1)\n\n# Splitting the fraudulent class\nX_val, X_test, y_val, y_test = train_test_split(X_1, y_1, test_size = 0.5, random_state = 40)\ndata_val_2, data_test_2 = pd.concat([X_val, y_val], axis = 1), pd.concat([X_test, y_test], axis = 1)\n\n# Merging data to construct the validation set and the test set\ndata_val, data_test = pd.concat([data_val_1, data_val_2], axis = 0), pd.concat([data_test_1, data_test_2], axis = 0)\nX_val, y_val = data_val.drop('Class', axis = 1), data_val['Class']\nX_test, y_test = data_test.drop('Class', axis = 1), data_test['Class']\n```\n:::\n\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\n# Distribution of authentic and fraudulent transactions over training, validation and test set\nlabels = ['Train', 'Validation', 'Test']\nvalues_0 = [len(y_train[y_train == 0]), len(y_val[y_val == 0]), len(y_test[y_test == 0])]\nvalues_1 = [len(y_train[y_train == 1]), len(y_val[y_val == 1]), len(y_test[y_test == 1])]\nfig = make_subplots(rows = 1, cols = 2, specs = [[{'type': 'domain'}, {'type': 'domain'}]])\nfig.add_trace(go.Pie(values = values_0, labels = labels, hole = 0.5, textinfo = 'percent', title = \"Authentic\"),\n              row = 1, col = 1)\nfig.add_trace(go.Pie(values = values_1, labels = labels, hole = 0.5, textinfo = 'percent', title = \"Fraudulent\"),\n              row = 1, col = 2)\ntext_title = \"Distribution of authentic and fraudulent transactions over training, validation and test set\"\nfig.update_layout(height = 500, width = 800, showlegend = True, title = dict(text = text_title, x = 0.5, y = 0.95)) \nfig.show()\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<div>                            <div id=\"24c51716-c69d-4830-9c87-a4ccf78af469\" class=\"plotly-graph-div\" style=\"height:500px; width:800px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"24c51716-c69d-4830-9c87-a4ccf78af469\")) {                    Plotly.newPlot(                        \"24c51716-c69d-4830-9c87-a4ccf78af469\",                        [{\"hole\":0.5,\"labels\":[\"Train\",\"Validation\",\"Test\"],\"textinfo\":\"percent\",\"title\":{\"text\":\"Authentic\"},\"values\":[227452,28431,28432],\"type\":\"pie\",\"domain\":{\"x\":[0.0,0.45],\"y\":[0.0,1.0]}},{\"hole\":0.5,\"labels\":[\"Train\",\"Validation\",\"Test\"],\"textinfo\":\"percent\",\"title\":{\"text\":\"Fraudulent\"},\"values\":[0,246,246],\"type\":\"pie\",\"domain\":{\"x\":[0.55,1.0],\"y\":[0.0,1.0]}}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Distribution of authentic and fraudulent transactions over training, validation and test set\",\"x\":0.5,\"y\":0.95},\"height\":500,\"width\":800,\"showlegend\":true},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('24c51716-c69d-4830-9c87-a4ccf78af469');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\n# Setting the number of bins\nbins_train = math.floor(len(X_train)**(1/3))\n```\n:::\n\n\n## Feature Engineering\n\n### Time\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\n# Decomposing time\nfor df in [X_train, X_val, X_test]:\n    df['Day'], temp = df['Time'] // (24*60*60), df['Time'] % (24*60*60)\n    df['Hour'], temp = temp // (60*60), temp % (60*60)\n    df['Minute'], df['Second'] = temp // 60, temp % 60\nX_train[['Time', 'Day', 'Hour', 'Minute', 'Second']].head()\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>Day</th>\n      <th>Hour</th>\n      <th>Minute</th>\n      <th>Second</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>19594</th>\n      <td>30401.0</td>\n      <td>0.0</td>\n      <td>8.0</td>\n      <td>26.0</td>\n      <td>41.0</td>\n    </tr>\n    <tr>\n      <th>124712</th>\n      <td>77397.0</td>\n      <td>0.0</td>\n      <td>21.0</td>\n      <td>29.0</td>\n      <td>57.0</td>\n    </tr>\n    <tr>\n      <th>167920</th>\n      <td>118964.0</td>\n      <td>1.0</td>\n      <td>9.0</td>\n      <td>2.0</td>\n      <td>44.0</td>\n    </tr>\n    <tr>\n      <th>47377</th>\n      <td>43191.0</td>\n      <td>0.0</td>\n      <td>11.0</td>\n      <td>59.0</td>\n      <td>51.0</td>\n    </tr>\n    <tr>\n      <th>41731</th>\n      <td>40804.0</td>\n      <td>0.0</td>\n      <td>11.0</td>\n      <td>20.0</td>\n      <td>4.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\n# Visualization\nfig, ax = plt.subplots(1, 2, figsize = (15, 6), sharey = False)\nsns.histplot(data = X_train, x = 'Time', bins = bins_train, ax = ax[0])\nsns.histplot(data = X_train, x = 'Hour', bins = 24, ax = ax[1])\nax[1].set_ylabel(\" \")\nplt.suptitle(\"Histograms of Time and Hour\", size = 14)\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-9-output-1.png){width=1424 height=566}\n:::\n:::\n\n\n## Amount\nThe distribution of Amount has extreme positive skewness. We apply the transformation  x↦log(x+0.001)\n  to this column and form the new column Amount_transformed. The positive constant  0.001\n  is added to deal with the zero-amount transactions, which leads to  log 0, an undefined quantity.\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\n# Transformation of 'Amount'\nfor df in [X_train, X_val, X_test]:\n    df['Amount_transformed'] = np.log10(df['Amount'] + 0.001)\n```\n:::\n\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\n# Visualization\nfig, ax = plt.subplots(1, 2, figsize = (15, 6), sharey = False)\nsns.histplot(data = X_train, x = 'Amount', bins = bins_train, ax = ax[0])\nsns.histplot(data = X_train, x = 'Amount_transformed', bins = bins_train, ax = ax[1])\nax[1].set_ylabel(\" \")\nplt.suptitle(\"Histograms of Amount and Amount_transformed\", size = 14)\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-11-output-1.png){width=1425 height=566}\n:::\n:::\n\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\n# Discarding unnecessary columns\nfor df in [X_train, X_val, X_test]:\n    df.drop(['Time', 'Day', 'Minute', 'Second', 'Amount'], axis = 1, inplace = True)\n```\n:::\n\n\n# Feature Selection\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\n# Comparison of feature distributions for different target classes\ndata_val = pd.concat([X_val, y_val], axis = 1)\ndata_val_0, data_val_1 = data_val[data_val['Class'] == 0], data_val[data_val['Class'] == 1]\ncols, ncols = list(X_val.columns), 3\nnrows = math.ceil(len(cols) / ncols)\nfig, ax = plt.subplots(nrows, ncols, figsize = (4.5 * ncols, 4 * nrows))\nfor i in range(len(cols)):\n    sns.kdeplot(data_val_0[cols[i]], ax = ax[i // ncols, i % ncols])\n    sns.kdeplot(data_val_1[cols[i]], ax = ax[i // ncols, i % ncols])\n    if i % ncols != 0:\n        ax[i // ncols, i % ncols].set_ylabel(\" \")\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-13-output-1.png){width=1280 height=3824}\n:::\n:::\n\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\n# Feature selection\ncols = ['V4', 'V11', 'V12', 'V14', 'V16', 'V17', 'V18', 'V19', 'Hour']\nX_train_fs, X_val_fs, X_test_fs = X_train[cols], X_val[cols], X_test[cols]\nX_train_fs.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=13}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>V4</th>\n      <th>V11</th>\n      <th>V12</th>\n      <th>V14</th>\n      <th>V16</th>\n      <th>V17</th>\n      <th>V18</th>\n      <th>V19</th>\n      <th>Hour</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>19594</th>\n      <td>-0.706232</td>\n      <td>2.027925</td>\n      <td>0.535822</td>\n      <td>0.250769</td>\n      <td>0.773615</td>\n      <td>0.449717</td>\n      <td>-1.963208</td>\n      <td>0.613481</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>124712</th>\n      <td>1.474933</td>\n      <td>-1.154523</td>\n      <td>0.263527</td>\n      <td>0.316174</td>\n      <td>-1.029415</td>\n      <td>1.030772</td>\n      <td>-0.438839</td>\n      <td>0.529080</td>\n      <td>21.0</td>\n    </tr>\n    <tr>\n      <th>167920</th>\n      <td>4.840766</td>\n      <td>-2.242431</td>\n      <td>0.034829</td>\n      <td>-0.546349</td>\n      <td>-0.070375</td>\n      <td>1.033695</td>\n      <td>0.531801</td>\n      <td>1.215045</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>47377</th>\n      <td>0.565273</td>\n      <td>-0.157045</td>\n      <td>-0.548790</td>\n      <td>0.419194</td>\n      <td>0.183518</td>\n      <td>-0.681323</td>\n      <td>0.911357</td>\n      <td>1.318132</td>\n      <td>11.0</td>\n    </tr>\n    <tr>\n      <th>41731</th>\n      <td>-0.428860</td>\n      <td>-0.580964</td>\n      <td>-0.609099</td>\n      <td>-0.187948</td>\n      <td>1.226723</td>\n      <td>0.104368</td>\n      <td>-0.995711</td>\n      <td>0.420557</td>\n      <td>11.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Implementing Anomaly Detection\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\n# Normal pdf\ndef normal_density(x, mu, sigma):\n    \"\"\"\n    Computes univariate normal probability density function (pdf) with mean mu, standard deviation sigma\n    Args:\n      x (scalar)    : input observation\n      mu (scalar)   : mean\n      sigma (scalar): standard deviation (> 0)\n    Returns:\n      f (scalar): value of the univariate normal pdf\n    \"\"\"\n    assert sigma > 0, \"Standard deviation must be positive\"\n    f = (1 / (sigma * np.sqrt(2 * np.pi))) * np.exp(- (1 / 2) * ((x - mu) / sigma)**2)\n    return f\n```\n:::\n\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\n# Product of normal pdfs\ndef normal_product(x_vec, mu_vec, sigma_vec):\n    \"\"\"\n    Computes product of univariate normal densities\n    Args:\n      x_vec (array_like, shape (n,))    : vector of input observations\n      mu_vec (array_like, shape (n,))   : vector of means\n      sigma_vec (array_like, shape (n,)): vector of standard deviations (> 0)\n    Returns:\n      f (scalar): product of univariate normal densities\n    \"\"\"\n    assert min(sigma_vec) > 0, \"Standard deviation must be positive\"\n    assert len(mu_vec) == len(x_vec), \"Length of mean vector does not match length of input vector\"\n    assert len(sigma_vec) == len(x_vec), \"Length of standard deviation vector does not match length of input vector\"\n    f = 1\n    for i in range(len(x_vec)):\n        f = f * normal_density(x_vec[i], mu_vec[i], sigma_vec[i])\n    return f\n```\n:::\n\n\nNext, we compute the vector of means and vector of standard deviations for the features in the training set. These estimates characterize the joint probability density function of the features, which will be used to detect anomalous observations.\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\n# Model fitting\nmu_train, sigma_train = X_train_fs.mean(), X_train_fs.std()\n```\n:::\n\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\n# Function to predict anomaly based on probability density threshold\ndef model_normal(X, epsilon):\n    \"\"\"\n    Anomaly detection model\n    Args:\n      X (DataFrame, shape (m, n)): DataFrame of features\n      epsilon (scalar)           : threshold density value (> 0)\n    Returns:\n      y (array_like, shape (m,)): predicted class labels\n    \"\"\"\n    y = []\n    for i in X.index:\n        prob_density = normal_product(X.loc[i].tolist(), mu_train, sigma_train)\n        y.append((prob_density < epsilon).astype(int))\n    return y\n```\n:::\n\n\n## Threshold Tuning on Validation Set\nFirst, we construct some functions to compute and display the confusion matrix and to compute the  F2-score, given the true labels and the predicted labels of the target.\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\n# Function to compute confusion matrix\ndef conf_mat(y_test, y_pred):\n    \"\"\"\n    Computes confusion matrix\n    Args:\n      y_test (array_like): true binary (0 or 1) labels\n      y_pred (array_like): predicted binary (0 or 1) labels\n    Returns:\n      confusion_mat (array): A 2D array representing a 2x2 confusion matrix\n    \"\"\"\n    y_test, y_pred = list(y_test), list(y_pred)\n    count, labels, confusion_mat = len(y_test), [0, 1], np.zeros(shape = (2, 2), dtype = int)\n    for i in range(2):\n        for j in range(2):\n            confusion_mat[i][j] = len([k for k in range(count) if y_test[k] == labels[i] and y_pred[k] == labels[j]])\n    return confusion_mat\n```\n:::\n\n\n::: {.cell execution_count=19}\n``` {.python .cell-code}\n# Function to print confusion matrix\ndef conf_mat_heatmap(y_test, y_pred):\n    \"\"\"\n    Prints confusion matrix\n    Args:\n      y_test (array_like): true binary (0 or 1) labels\n      y_pred (array_like): predicted binary (0 or 1) labels\n    Returns:\n      Nothing, prints a heatmap representing a 2x2 confusion matrix\n    \"\"\"\n    confusion_mat = conf_mat(y_test, y_pred)\n    labels, confusion_mat_df = [0, 1], pd.DataFrame(confusion_mat, range(2), range(2))\n    plt.figure(figsize = (6, 4.75))\n    sns.heatmap(confusion_mat_df, annot = True, annot_kws = {\"size\": 16}, fmt = 'd')\n    plt.xticks([0.5, 1.5], labels, rotation = 'horizontal')\n    plt.yticks([0.5, 1.5], labels, rotation = 'horizontal')\n    plt.xlabel(\"Predicted label\", fontsize = 14)\n    plt.ylabel(\"True label\", fontsize = 14)\n    plt.title(\"Confusion Matrix\", fontsize = 14)\n    plt.grid(False)\n    plt.show()\n```\n:::\n\n\n::: {.cell execution_count=20}\n``` {.python .cell-code}\n# Function to compute and return f2_score\ndef f2_score(y_test, y_pred):\n    \"\"\"\n    Computes accuracy, given true and predicted binary (0 or 1) labels\n    Args:\n      y_test (array_like): true binary (0 or 1) labels\n      y_pred (array_like): predicted binary (0 or 1) labels\n    Returns:\n      f2 (float): accuracy obtained from y_test and y_pred\n    \"\"\"\n    confusion_mat = conf_mat(y_test, y_pred)\n    tn, fp, fn, tp = confusion_mat[0, 0], confusion_mat[0, 1], confusion_mat[1, 0], confusion_mat[1, 1]\n    f2 = (5 * tp) / ((5 * tp) + (4 * fn) + fp)\n    return f2\n```\n:::\n\n\n::: {.cell execution_count=21}\n``` {.python .cell-code}\n# Tuning the threshold of density value\nalpha_list, f2_list, f2_max, alpha_opt, y_val_pred_opt = [], [], 0.0, 0.0, np.zeros(len(y_val))\nfor alpha, j in itertools.product(np.arange(0.001, 0.051, 0.001), range(1)):\n    y_val_pred = model_normal(X_val_fs, epsilon = alpha**X_val_fs.shape[1])\n    f2 = f2_score(y_val, y_val_pred)\n    alpha_list.append(alpha)\n    f2_list.append(f2)\n    if f2 > f2_max:\n        alpha_opt = alpha\n        y_val_pred_opt = y_val_pred\n        f2_max = f2\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<script type=\"application/vnd.jupyter.widget-view+json\">\n{\"model_id\":\"e298556207244c728ca9faf10920626e\",\"version_major\":2,\"version_minor\":0,\"quarto_mimetype\":\"application/vnd.jupyter.widget-view+json\"}\n</script>\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nC:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_47740\\516892871.py:17: FutureWarning:\n\nSeries.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n\n```\n:::\n:::\n\n\n::: {.cell execution_count=22}\n``` {.python .cell-code}\n# Plotting F2-score over alpha\nplt.figure(figsize = (9, 6))\nplt.plot(alpha_list, f2_list)\nplt.xlabel(\"alpha\", fontsize = 14)\nplt.ylabel(\"F2-score\", fontsize = 14)\nplt.title(\"F2-score vs alpha\", fontsize = 14)\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-23-output-1.png){width=848 height=559}\n:::\n:::\n\n\n::: {.cell execution_count=23}\n``` {.python .cell-code}\n# Tuning summary\nprint(pd.Series({\n    \"Optimal alpha\": alpha_opt,\n    \"Optimal F2-score\": f2_score(y_val, y_val_pred_opt)\n}).to_string())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOptimal alpha       0.009000\nOptimal F2-score    0.834671\n```\n:::\n:::\n\n\n::: {.cell execution_count=24}\n``` {.python .cell-code}\n# Confusion matrix for predictions on the validation set\nconf_mat_heatmap(y_val, y_val_pred_opt)\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-25-output-1.png){width=513 height=441}\n:::\n:::\n\n\n## Prediction and Evaluation on Test Set\n\n::: {.cell execution_count=25}\n``` {.python .cell-code}\n# Function to compute and print evaluation metrics\ndef evaluation(y_test, y_pred):\n    confusion_mat = conf_mat(y_test, y_pred)\n    tn, fp, fn, tp = confusion_mat[0, 0], confusion_mat[0, 1], confusion_mat[1, 0], confusion_mat[1, 1]\n    print(pd.Series({\n        \"Accuracy\": (tp + tn) / (tn + fp + fn + tp),\n        \"Precision\": tp / (tp + fp),\n        \"Recall\": tp / (tp + fn),\n        \"F1-score\": (2 * tp) / ((2 * tp) + fn + fp),\n        \"F2-score\": (5 * tp) / ((5 * tp) + (4 * fn) + fp),\n        \"MCC\": ((tp * tn) - (fp * fn)) / np.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n    }).to_string())\n```\n:::\n\n\n::: {.cell execution_count=26}\n``` {.python .cell-code}\n# Prediction and evaluation on the test set\ny_test_normal = model_normal(X_test_fs, epsilon = alpha_opt**X_test_fs.shape[1])\nevaluation(y_test, y_test_normal)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nC:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_47740\\516892871.py:17: FutureWarning:\n\nSeries.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n\nC:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_47740\\2892512474.py:11: RuntimeWarning:\n\noverflow encountered in scalar multiply\n\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nAccuracy       0.996687\nPrecision      0.798419\nRecall         0.821138\nF1-score       0.809619\nF2-score       0.816492\nMCC          171.242437\n```\n:::\n:::\n\n\n::: {.cell execution_count=27}\n``` {.python .cell-code}\n# Confusion matrix for predictions on the test set\nconf_mat_heatmap(y_test, y_test_normal)\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-28-output-1.png){width=513 height=441}\n:::\n:::\n\n\n## Conclusion\n\nHere, we addressed the challenge of a highly imbalanced dataset in credit card transactions, where fraudulent transactions are significantly less frequent compared to legitimate ones. The approach involved sophisticated feature engineering, where we extracted 'Hour' from the 'Time' attribute and log-transformed the 'Amount' feature to correct for skewness, resulting in a new feature called 'Amount_transformed'.\n\nA crucial step in the analysis was the selection of key features that show distinct distribution patterns across the two classes of transactions. Out of 30 features engineered, 9 (V4, V11, V12, V14, V16, V17, V18, V19, and Hour) were identified as significantly influential in distinguishing between fraudulent and legitimate transactions. These features were used to fit a multivariate normal distribution to the training data, under the assumption of statistical independence among features, a reasonable assumption given that most of the features were obtained through PCA.\n\nThe final phase of the project involved optimizing a threshold for anomaly detection. This was achieved by iterating over a range of values and evaluating their performance using the F2-score on the validation set. The optimal threshold was found to be approximately 0.0099. With this threshold, the model achieved an F2-score of 0.834671 on the validation set. When applied to the test set, the model demonstrated a consistent performance with an F2-score of 0.816492. This method proved effective in flagging transactions as fraudulent based on their density values in the fitted distribution.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n<script type=\"text/javascript\">\nwindow.PlotlyConfig = {MathJaxConfig: 'local'};\nif (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\nif (typeof require !== 'undefined') {\nrequire.undef(\"plotly\");\nrequirejs.config({\n    paths: {\n        'plotly': ['https://cdn.plot.ly/plotly-2.27.0.min']\n    }\n});\nrequire(['plotly'], function(Plotly) {\n    window._Plotly = Plotly;\n});\n}\n</script>\n\n<script src=\"https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js\" crossorigin=\"anonymous\"></script>\n"
      ],
      "include-after-body": [
        "<script type=application/vnd.jupyter.widget-state+json>\n{\"state\":{\"02153720c11a4617b2ddc3774e5db5ec\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"ProgressStyleModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"ProgressStyleModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"StyleView\",\"bar_color\":null,\"description_width\":\"\"}},\"112ee470c70842fd8bcbb3c2762b1bbc\":{\"model_module\":\"@jupyter-widgets/base\",\"model_module_version\":\"2.0.0\",\"model_name\":\"LayoutModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/base\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"LayoutModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"LayoutView\",\"align_content\":null,\"align_items\":null,\"align_self\":null,\"border_bottom\":null,\"border_left\":null,\"border_right\":null,\"border_top\":null,\"bottom\":null,\"display\":null,\"flex\":null,\"flex_flow\":null,\"grid_area\":null,\"grid_auto_columns\":null,\"grid_auto_flow\":null,\"grid_auto_rows\":null,\"grid_column\":null,\"grid_gap\":null,\"grid_row\":null,\"grid_template_areas\":null,\"grid_template_columns\":null,\"grid_template_rows\":null,\"height\":null,\"justify_content\":null,\"justify_items\":null,\"left\":null,\"margin\":null,\"max_height\":null,\"max_width\":null,\"min_height\":null,\"min_width\":null,\"object_fit\":null,\"object_position\":null,\"order\":null,\"overflow\":null,\"padding\":null,\"right\":null,\"top\":null,\"visibility\":null,\"width\":null}},\"13e32bdcb2c14cba8f696109982de5bc\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"FloatProgressModel\",\"state\":{\"_dom_classes\":[],\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"FloatProgressModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/controls\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"ProgressView\",\"bar_style\":\"success\",\"description\":\"\",\"description_allow_html\":false,\"layout\":\"IPY_MODEL_69c95089bc42455eab2f875ce7d4311d\",\"max\":50,\"min\":0,\"orientation\":\"horizontal\",\"style\":\"IPY_MODEL_02153720c11a4617b2ddc3774e5db5ec\",\"tabbable\":null,\"tooltip\":null,\"value\":50}},\"69c95089bc42455eab2f875ce7d4311d\":{\"model_module\":\"@jupyter-widgets/base\",\"model_module_version\":\"2.0.0\",\"model_name\":\"LayoutModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/base\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"LayoutModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"LayoutView\",\"align_content\":null,\"align_items\":null,\"align_self\":null,\"border_bottom\":null,\"border_left\":null,\"border_right\":null,\"border_top\":null,\"bottom\":null,\"display\":null,\"flex\":null,\"flex_flow\":null,\"grid_area\":null,\"grid_auto_columns\":null,\"grid_auto_flow\":null,\"grid_auto_rows\":null,\"grid_column\":null,\"grid_gap\":null,\"grid_row\":null,\"grid_template_areas\":null,\"grid_template_columns\":null,\"grid_template_rows\":null,\"height\":null,\"justify_content\":null,\"justify_items\":null,\"left\":null,\"margin\":null,\"max_height\":null,\"max_width\":null,\"min_height\":null,\"min_width\":null,\"object_fit\":null,\"object_position\":null,\"order\":null,\"overflow\":null,\"padding\":null,\"right\":null,\"top\":null,\"visibility\":null,\"width\":null}},\"839d38b402eb4dc792f9b8d3d8bc1a52\":{\"model_module\":\"@jupyter-widgets/base\",\"model_module_version\":\"2.0.0\",\"model_name\":\"LayoutModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/base\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"LayoutModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"LayoutView\",\"align_content\":null,\"align_items\":null,\"align_self\":null,\"border_bottom\":null,\"border_left\":null,\"border_right\":null,\"border_top\":null,\"bottom\":null,\"display\":null,\"flex\":null,\"flex_flow\":null,\"grid_area\":null,\"grid_auto_columns\":null,\"grid_auto_flow\":null,\"grid_auto_rows\":null,\"grid_column\":null,\"grid_gap\":null,\"grid_row\":null,\"grid_template_areas\":null,\"grid_template_columns\":null,\"grid_template_rows\":null,\"height\":null,\"justify_content\":null,\"justify_items\":null,\"left\":null,\"margin\":null,\"max_height\":null,\"max_width\":null,\"min_height\":null,\"min_width\":null,\"object_fit\":null,\"object_position\":null,\"order\":null,\"overflow\":null,\"padding\":null,\"right\":null,\"top\":null,\"visibility\":null,\"width\":null}},\"8d645e0ed05140cfbd7df2cf81765cc4\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"HTMLModel\",\"state\":{\"_dom_classes\":[],\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"HTMLModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/controls\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"HTMLView\",\"description\":\"\",\"description_allow_html\":false,\"layout\":\"IPY_MODEL_c4799843e65448ff9606baa656c5a286\",\"placeholder\":\"​\",\"style\":\"IPY_MODEL_d47a49af64194d908b53c51bb2650433\",\"tabbable\":null,\"tooltip\":null,\"value\":\" 50/50 [04:41&lt;00:00,  5.69s/it]\"}},\"bd213a7ecb4d49d89d68603536c361dc\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"HTMLModel\",\"state\":{\"_dom_classes\":[],\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"HTMLModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/controls\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"HTMLView\",\"description\":\"\",\"description_allow_html\":false,\"layout\":\"IPY_MODEL_839d38b402eb4dc792f9b8d3d8bc1a52\",\"placeholder\":\"​\",\"style\":\"IPY_MODEL_c39e1fa13d794c4ca478208ca216a1cc\",\"tabbable\":null,\"tooltip\":null,\"value\":\"100%\"}},\"c39e1fa13d794c4ca478208ca216a1cc\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"HTMLStyleModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"HTMLStyleModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"StyleView\",\"background\":null,\"description_width\":\"\",\"font_size\":null,\"text_color\":null}},\"c4799843e65448ff9606baa656c5a286\":{\"model_module\":\"@jupyter-widgets/base\",\"model_module_version\":\"2.0.0\",\"model_name\":\"LayoutModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/base\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"LayoutModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"LayoutView\",\"align_content\":null,\"align_items\":null,\"align_self\":null,\"border_bottom\":null,\"border_left\":null,\"border_right\":null,\"border_top\":null,\"bottom\":null,\"display\":null,\"flex\":null,\"flex_flow\":null,\"grid_area\":null,\"grid_auto_columns\":null,\"grid_auto_flow\":null,\"grid_auto_rows\":null,\"grid_column\":null,\"grid_gap\":null,\"grid_row\":null,\"grid_template_areas\":null,\"grid_template_columns\":null,\"grid_template_rows\":null,\"height\":null,\"justify_content\":null,\"justify_items\":null,\"left\":null,\"margin\":null,\"max_height\":null,\"max_width\":null,\"min_height\":null,\"min_width\":null,\"object_fit\":null,\"object_position\":null,\"order\":null,\"overflow\":null,\"padding\":null,\"right\":null,\"top\":null,\"visibility\":null,\"width\":null}},\"d47a49af64194d908b53c51bb2650433\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"HTMLStyleModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"HTMLStyleModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"StyleView\",\"background\":null,\"description_width\":\"\",\"font_size\":null,\"text_color\":null}},\"e298556207244c728ca9faf10920626e\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"HBoxModel\",\"state\":{\"_dom_classes\":[],\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"HBoxModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/controls\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"HBoxView\",\"box_style\":\"\",\"children\":[\"IPY_MODEL_bd213a7ecb4d49d89d68603536c361dc\",\"IPY_MODEL_13e32bdcb2c14cba8f696109982de5bc\",\"IPY_MODEL_8d645e0ed05140cfbd7df2cf81765cc4\"],\"layout\":\"IPY_MODEL_112ee470c70842fd8bcbb3c2762b1bbc\",\"tabbable\":null,\"tooltip\":null}}},\"version_major\":2,\"version_minor\":0}\n</script>\n"
      ]
    }
  }
}